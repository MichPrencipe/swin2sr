{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michele.prencipe/environments/miniforge3/envs/transformer/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('/home/michele.prencipe/tesi/transformer/swin2sr')\n",
    "\n",
    "os.chdir('/home/michele.prencipe/tesi/transformer/swin2sr')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from data_loader.read_mrc import read_mrc\n",
    "from skimage import io, color\n",
    "from utils.utils import set_global_seed\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torchvision.io.image\")\n",
    "\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "set_global_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader.biosr_dataset import BioSRDataLoader\n",
    "\n",
    "# Define your working directory and data directory\n",
    "work_dir = \".\"\n",
    "tensorboard_log_dir = os.path.join(work_dir, \"tensorboard_logs\")\n",
    "os.makedirs(tensorboard_log_dir, exist_ok=True)\n",
    "data_dir = '/group/jug/ashesh/data/BioSR/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swin2SR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     config \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Initialize the model\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSwin2SRModule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_directory,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m87d8vg2xswin2sr_best.ckpt\u001b[39m\u001b[38;5;124m'\u001b[39m))[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/tesi/transformer/swin2sr/models/swin2sr.py:29\u001b[0m, in \u001b[0;36mSwin2SRModule.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28msuper\u001b[39m(Swin2SRModule, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()        \n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# self.model = Swin2SR(\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#     upscale=1, in_chans=1, img_size=(256, 256),\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#     window_size=16, img_range=1., depths=[3, 3],\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#     embed_dim=60, num_heads=[3, 3], mlp_ratio=2,\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#     upsampler='pixelshuffledirect'\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m Swin2SR(\n\u001b[0;32m---> 29\u001b[0m     upscale\u001b[38;5;241m=\u001b[39m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mupscale, \n\u001b[1;32m     30\u001b[0m     in_chans \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39min_chans,\n\u001b[1;32m     31\u001b[0m     img_size\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mimg_size,\n\u001b[1;32m     32\u001b[0m     window_size\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mwindow_size, \n\u001b[1;32m     33\u001b[0m     img_range\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mimg_range, \n\u001b[1;32m     34\u001b[0m     depths\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdepths,\n\u001b[1;32m     35\u001b[0m     embed_dim\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39membed_dim, \n\u001b[1;32m     36\u001b[0m     num_heads\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m     37\u001b[0m     mlp_ratio\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmlp_ratio,\n\u001b[1;32m     38\u001b[0m     upsampler\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mupsampler,\n\u001b[1;32m     39\u001b[0m     patch_size\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpatch_size\n\u001b[1;32m     40\u001b[0m )\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(config)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# config_dict = {'upscale': 1,\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m#                'in_chans': 1,\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m#                'img_size': (256, 256),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# self.model = Swin2SR(**config_dict)\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "from tests.training import Swin2SRModule\n",
    "import json\n",
    "\n",
    "model_directory = '/group/jug/Michele/training/2411/biosr/617/'\n",
    "config_fpath = os.path.join(model_directory,'config.json')\n",
    "with open(config_fpath,'rb') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Initialize the model\n",
    "model = Swin2SRModule(config)\n",
    "\n",
    "model.load_state_dict(torch.load(os.path.join(model_directory,'87d8vg2xswin2sr_best.ckpt'))['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stitching Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = 'biosr'#config.data.data_type\n",
    "gauss_factor = 13600 #config.data.gaussian_factor\n",
    "poisson_factor = 0# config.data.poisson_factor\n",
    "noisy_data = True#config.data.noisy\n",
    "patch_size = 256\n",
    "tile_size = 128\n",
    "\n",
    "data_shape = (5,1004,1004)#config.data.data_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from predtiler.dataset import get_tiling_dataset, get_tile_manager\n",
    "from data_loader.biosr_dataloader import SplitDataset\n",
    "\n",
    "manager = get_tile_manager(data_shape=data_shape, tile_shape=(1,tile_size,tile_size), \n",
    "                               patch_shape=(1,patch_size,patch_size))\n",
    "\n",
    "    \n",
    "dset_class = get_tiling_dataset(SplitDataset, manager)\n",
    "dataset = dset_class(           data_type = data_type,\n",
    "                                patch_size=patch_size,\n",
    "                                transform=None,\n",
    "                                noisy_data=noisy_data,\n",
    "                                poisson_factor=poisson_factor, \n",
    "                                gaus_factor=gauss_factor,\n",
    "                                mode = 'Test'\n",
    "                                )\n",
    "print(type(dataset))\n",
    "test_loader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=12)\n",
    "c1_min, c1_max, c2_min, c2_max = test_loader.dataset.get_normalization_params() #of the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from predtiler.tile_stitcher import stitch_predictions\n",
    "\n",
    "predictions = []\n",
    "targets = []\n",
    "model = model.eval()\n",
    "model = model.cuda()\n",
    "inputs = []\n",
    "\n",
    "for inp, targ in test_loader:\n",
    "    inp, targ = inp.cuda(), targ.cuda()\n",
    "    if len(inp.shape) == 3:  \n",
    "        inp = inp.unsqueeze(1)\n",
    "    if len(targ.shape) == 3:\n",
    "        targ = targ.unsqueeze(1)        \n",
    "    pred = model(inp)\n",
    "    \n",
    "    \n",
    "    pred[:,0,:,:] = pred[:,0,:,:]*(c1_max - c1_min) + c1_min\n",
    "    pred[:,1,:,:] = pred[:,1,:,:]*(c2_max - c2_min) + c2_min\n",
    "    \n",
    "    predictions.append(pred.cpu().detach().numpy())\n",
    "    \n",
    "    \n",
    "    targ[:,0,:,:] = targ[:,0,:,:]*(c1_max - c1_min) + c1_min\n",
    "    targ[:,1,:,:] = targ[:,1,:,:]*(c2_max - c2_min) + c2_min\n",
    "    \n",
    "    inputs.append(inp.cpu().detach().numpy())\n",
    "    targets.append(targ.cpu().detach().numpy())\n",
    "\n",
    "inputs = np.concatenate(inputs, axis = 0)\n",
    "predictions = np.concatenate(predictions, axis = 0) # shape: (number_of_patches, C, patch_size, patch_size)\n",
    "stitched_pred = stitch_predictions(predictions, dataset.tile_manager)\n",
    "targets = np.concatenate(targets, axis = 0)\n",
    "print(targets.shape)\n",
    "print(manager)\n",
    "print(predictions.shape)\n",
    "print(stitched_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader.biosr_no_patching import NoPatchingSplitDataset\n",
    "dataset_no_patching = NoPatchingSplitDataset(\n",
    "                              data_type=data_type,\n",
    "                              transform=None,\n",
    "                              noisy_data=noisy_data,\n",
    "                              poisson_factor= poisson_factor, \n",
    "                              gaus_factor= gauss_factor, mode = 'Test')\n",
    "\n",
    "\n",
    "dataloader = DataLoader(dataset_no_patching, batch_size=2, shuffle=False, num_workers=4)\n",
    "c1_min, c1_max, c2_min, c2_max = test_loader.dataset.get_normalization_params() #of the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from predtiler.tile_stitcher import stitch_predictions\n",
    "\n",
    "predictions = []\n",
    "targets = []\n",
    "inputs = []\n",
    "\n",
    "for inp, targ in dataloader:\n",
    "    inp, targ = inp.cuda(), targ.cuda()\n",
    "    if len(inp.shape) == 3:  \n",
    "        inp = inp.unsqueeze(1)\n",
    "    if len(targ.shape) == 3:\n",
    "        targ = targ.unsqueeze(1)        \n",
    "    targ[:,0,:,:] = targ[:,0,:,:]*(c1_max - c1_min) + c1_min\n",
    "    targ[:,1,:,:] = targ[:,1,:,:]*(c2_max - c2_min) + c2_min\n",
    "    \n",
    "    targets.append(targ.cpu().detach().numpy())\n",
    "    inputs.append(inp.cpu().detach().numpy())\n",
    "    \n",
    "inputs = np.concatenate(inputs, axis = 0)\n",
    "targets = np.concatenate(targets, axis = 0)\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from utils.util_calculate_psnr_ssim import calculate_psnr, calculate_ssim\n",
    "from core.psnr import PSNR\n",
    "\n",
    "psnr_arr = {0: [], 1: []}\n",
    "for ch_idx in range(targets.shape[1]):\n",
    "    if ch_idx == 0:\n",
    "        data_range = c1_max - c1_min\n",
    "        \n",
    "    else: \n",
    "        data_range = c2_max - c2_min\n",
    "    psnr_arr[ch_idx].append(PSNR(targets[:,ch_idx,:,:], stitched_pred[:,:,:,ch_idx], range_= data_range))\n",
    "\n",
    "print(psnr_arr)\n",
    "psnr_1 = np.mean(psnr_arr[0])\n",
    "psnr_2 = np.mean(psnr_arr[1])\n",
    "print(\"psnr channel 1:\", np.mean(psnr_arr[0]))\n",
    "print(\"psnr channel 2:\", np.mean(psnr_arr[1]))\n",
    "print(np.mean([psnr_1, psnr_2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea la figura con 1 riga e 2 colonne\n",
    "fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 5, figsize=(100, 100))  # 1 riga, 2 colonne\n",
    "\n",
    "_, target = dataloader.dataset[0]\n",
    "\n",
    "\n",
    "# Primo subplot\n",
    "ax1.imshow(stitched_pred[0,:,:,0],vmin = targets[0,0,:,:].min())\n",
    "ax1.set_title('Stitched Pred 1')\n",
    "\n",
    "# Secondo subplot\n",
    "ax2.imshow(stitched_pred[0,:,:,1],vmin = targets[0,1,:,:].min())\n",
    "ax2.set_title('Stitched Pred 2')\n",
    "\n",
    "# Secondo subplot\n",
    "ax3.imshow(targets[0,0,:, :])\n",
    "ax3.set_title('Target Channel 1')\n",
    "\n",
    "\n",
    "# Secondo subplot\n",
    "ax4.imshow(targets[0,1,:,:])\n",
    "ax4.set_title('Target Channel 2')\n",
    "\n",
    "\n",
    "# Secondo subplot\n",
    "ax5.imshow(inputs[0,0, : , :])\n",
    "ax5.set_title('Input')\n",
    "\n",
    "\n",
    "# Mostra il grafico\n",
    "plt.tight_layout()  # Adatta il layout per evitare sovrapposizioni\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:transformer] *",
   "language": "python",
   "name": "conda-env-transformer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
